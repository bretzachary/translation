problem with getting two-gram count: it includes fluff like 'de la'. (stop words)
so to filter: the naive bayes trick from scikit tutorial (tfidf). alternatively, just filter manually selected words. can the trick identify words 'most associated' with article. or most important words across articles?



ideas:
next to article highlight noteworthy vocab (unique, common, etc)
maybe categoriza vcab by importance (frequency)
same as above - with definitions at top of articles. sort of a 'what to expect' section.
don't forget about a/b testing
harvard business review articles
blogs <- might be easiest ppl to reach out to (for licensing)


to do:
user_page('profile')  - can just start with articles read. maybe an optional button for 'read whole article/did not read whole article' would be a start.<-button can go at end of article. no need to annouce it elsewhere.

category/section page
category/section subsections on front page
accounts - articles read, vocab_stuff,  ?(achievements)

<!--        <a href="{% url 'track_article_pageviews' %}?article_id={{article.id}}>" -->

Article.objects.order_by('section').values_list('section', flat=True).distinct()

Article.objects.values_list('section', flat=True).distinct